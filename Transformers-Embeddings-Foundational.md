# Transformers
![image](https://learn.microsoft.com/en-us/training/wwl-data-ai/analyze-images-computer-vision/media/language-encoder.png)  
* Transformers work by processing huge volumes of data, and encoding language tokens (representing individual words or phrases) as vector-based embeddings (arrays of numeric values)
* Tokens that are semantically similar are encoded in similar positions, creating a semantic language model that makes it possible to build sophisticated NLP solutions for text analysis, translation, language generation, and other tasks.

# Transformers in Multi-Modal Models. Foundational Model. 
![image](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/assets/4239376/f8ea5f0a-9439-4384-bc40-633bb7818fd3)

* The **Microsoft Florence** model is just such a model. Trained with huge volumes of captioned images from the Internet, it includes both a language encoder and an image encoder. Florence is an example of a foundation model.
* In other words, a pre-trained general model on which you can build multiple adaptive models for specialist tasks.
![image](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/assets/4239376/7280bf7b-4d18-44a7-940e-192b8aa09225)
